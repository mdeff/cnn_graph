{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial 6: structured sequence modeling\n",
    "\n",
    "* Create simple parametric time series and try to model them.\n",
    "* Add structure by constructing a graph between the series and see how it improves.\n",
    "* Usage of `tflearn` inspired by [How to do time series prediction using RNNs, TensorFlow and Cloud ML Engine](https://medium.com/google-cloud/how-to-do-time-series-prediction-using-rnns-and-tensorflow-and-cloud-ml-engine-2ad2eeb189e8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (17, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('..', 'data', 'structured_sequence_trial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 1000\n",
    "N_SEQ = 40\n",
    "\n",
    "def create_time_series(seq_len, random_state):\n",
    "    freq = random_state.uniform(0.1, 0.6)\n",
    "    ampl = random_state.uniform(0.5, 1.5)\n",
    "    offset = random_state.uniform(-1, 1)\n",
    "    return np.sin(np.arange(seq_len) * freq) * ampl + offset\n",
    "\n",
    "rs = np.random.RandomState(42)\n",
    "data = np.empty((N_SEQ, SEQ_LEN))\n",
    "for i in range(N_SEQ):\n",
    "    data[i] = create_time_series(SEQ_LEN, rs)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:5, :100].T.plot();\n",
    "plt.savefig('time_series.pdf')\n",
    "# hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Graph construction\n",
    "\n",
    "k-NN graph between the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Data preparation\n",
    "\n",
    "* Store data in TFRecords files which will be read by the input pipeline.\n",
    "* Preprocessing can be done here.\n",
    "* Data augmentation should be done in input pipeline (to save disk space).\n",
    "* We are doing full batch, i.e. we feed data on the whole graph at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_INPUTS = 50  # Number of samples used for prediction, i.e. unrolling length.\n",
    "N_OUTPUTS = 1  # Number of samples in the time series the model tries to predict.\n",
    "\n",
    "def feature(array):\n",
    "    array = array.reshape(-1)\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list(array)))\n",
    "\n",
    "def save_dataset(data, filename):\n",
    "    \"\"\"Save dataset as TFRecords.\"\"\"\n",
    "    filename = os.path.join(DATA_DIR, filename)\n",
    "    num_examples = data.shape[1] - N_INPUTS - N_OUTPUTS + 1\n",
    "    assert num_examples > 0\n",
    "    tf.logging.info('Writing {} examples to {}'.format(num_examples, filename))\n",
    "    with tf.python_io.TFRecordWriter(filename) as writer:\n",
    "        for idx in range(num_examples):\n",
    "            inputs = data[:, idx:idx+N_INPUTS]\n",
    "            targets = data[:, idx+N_INPUTS:idx+N_INPUTS+N_OUTPUTS]\n",
    "            example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                #'graph': feature(graph),  # Adjacency matrix or Laplacian can be stored here.\n",
    "                'inputs': feature(inputs),\n",
    "                'targets': feature(targets)}))\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "TRAINING_LEN = int(0.8 * SEQ_LEN)\n",
    "save_dataset(data.iloc[:, :TRAINING_LEN].values, 'train.tfrecords')\n",
    "save_dataset(data.iloc[:, TRAINING_LEN:].values, 'validation.tfrecords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Data loading\n",
    "\n",
    "Two training schemes:\n",
    "* Load whole data for training up to a certain point in time. That is what is done for text (the whole vocabulary graph is used).\n",
    "* Use some time series (some part of the graph) as training and the others as evaluation.\n",
    "\n",
    "TF alternative:\n",
    "* [tf.contrib.slim.dataset](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "\n",
    "    def __init__(s, filenames, num_epochs=1, read_threads=1, seed=None):\n",
    "        #if mode == tflearn.ModeKeys.TRAIN:\n",
    "        s.filenames = filenames\n",
    "        s.num_epochs = num_epochs\n",
    "        s.read_threads = read_threads\n",
    "        s.seed = seed\n",
    "\n",
    "    def _read_and_decode(s, filename_queue):\n",
    "        reader = tf.TFRecordReader()\n",
    "        _, example = reader.read(filename_queue)\n",
    "        features={\n",
    "            'inputs': tf.FixedLenFeature([N_SEQ * N_INPUTS], tf.float32),\n",
    "            'targets': tf.FixedLenFeature([N_SEQ * N_OUTPUTS], tf.float32),\n",
    "        }\n",
    "        example = tf.parse_single_example(example, features)\n",
    "        inputs = tf.reshape(example['inputs'], [N_SEQ, N_INPUTS])\n",
    "        targets = tf.reshape(example['targets'], [N_SEQ, N_OUTPUTS])\n",
    "        return inputs, targets\n",
    "\n",
    "    def __call__(s):\n",
    "        with tf.name_scope('input_pipeline'):\n",
    "            with tf.device(\"/cpu:0\"):  # Input queues are on CPU.\n",
    "                filenames = [os.path.join(DATA_DIR, filename) for filename in s.filenames]\n",
    "                filename_queue = tf.train.string_input_producer(filenames, s.num_epochs, shuffle=True)\n",
    "\n",
    "                examples = [s._read_and_decode(filename_queue) for _ in range(s.read_threads)]\n",
    "\n",
    "                # Shuffle examples.\n",
    "                if True:\n",
    "                    min_after_dequeue = 10 #10000\n",
    "                    capacity = min_after_dequeue + (s.read_threads + 2)  # * s.batch_size\n",
    "                    inputs, targets = tf.train.shuffle_batch_join(\n",
    "                            examples, batch_size=1, seed=s.seed, capacity=capacity,\n",
    "                            min_after_dequeue=min_after_dequeue, allow_smaller_final_batch=True)\n",
    "                    # We read full batch.\n",
    "                    inputs = inputs[0, ...]\n",
    "                    targets = targets[0, ...]\n",
    "                else:\n",
    "                    assert s.read_threads == 1\n",
    "                    inputs, targets = examples[0]\n",
    "\n",
    "                # Can return a fixed graph or a per-sample graph in the features.\n",
    "                return {'inputs': inputs}, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make one pass over the dataset to make sure the input pipeline works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = DataLoader(['train.tfrecords'])()[0]['inputs']\n",
    "\n",
    "sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess, coord)\n",
    "\n",
    "idx = 0\n",
    "training_data = np.empty((N_SEQ, TRAINING_LEN-N_OUTPUTS))\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        training_data[:, idx:idx+N_INPUTS] = sess.run(inputs)\n",
    "        idx += 1\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done: {} steps'.format(idx))\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "\n",
    "coord.join(threads)\n",
    "sess.close()\n",
    "\n",
    "#np.testing.assert_allclose(training_data, data.iloc[:, :TRAINING_LEN-N_OUTPUTS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Sequence modeling\n",
    "\n",
    "We can either:\n",
    "* assume the same dynamic on all time series and train a shared model\n",
    "* train a model for each time series (which still has access to its neighbors)\n",
    "* mix: e.g. per times series bias or last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of hidden units in each of the LSTM cells.\n",
    "# Number of filters in case of GCN.\n",
    "LSTM_SIZE = 3\n",
    "\n",
    "def model(features, targets, mode, params):\n",
    "    # Reformat input shape to become a sequence.\n",
    "    x = tf.split(features['inputs'], N_INPUTS, axis=1)\n",
    "    \n",
    "    # Recurrent neural network followed by linear transform.\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(LSTM_SIZE, forget_bias=1.0)\n",
    "    outputs, _ = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    #outputs, _ = tf.contrib.rnn.dynamic_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    \n",
    "    tf.summary.histogram('hidden', outputs[-1])\n",
    "    predictions = tf.contrib.layers.fully_connected(outputs[-1], N_OUTPUTS, activation_fn=None)\n",
    "    \n",
    "    # Loss function and metric for training and evaluation.\n",
    "    loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "    eval_metric_ops = {\n",
    "        'rmse': tf.metrics.root_mean_squared_error(targets, predictions)\n",
    "    }\n",
    "    \n",
    "    # Training operations.\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step(),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        #learning_rate_decay_fn=lambda lr, gs: tf.train.exponential_decay(lr, gs, 100e3, 0.96, staircase=True),\n",
    "        optimizer=lambda lr: tf.train.GradientDescentOptimizer(lr),\n",
    "        #optimizer=lambda lr: tf.train.MomentumOptimizer(lr, 0.9),\n",
    "    )\n",
    "    \n",
    "    return tflearn.ModelFnOps(\n",
    "        mode=mode,\n",
    "        predictions={'predictions': predictions},\n",
    "        loss=loss,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops=eval_metric_ops,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing variables.\n",
    "#tflearn.monitors.ValidationMonitor\n",
    "#tf.train.SessionRunHook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning the hyper-parameters.\n",
    "#tflearn.learn_runner.run()\n",
    "#tflearn.learn_runner.tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF debugger.\n",
    "from tensorflow.python import debug as tfdbg\n",
    "\n",
    "hooks = [tfdbg.LocalCLIDebugHook()]\n",
    "hooks = [tfdbg.DumpingDebugHook('tfdbg_dumps')]\n",
    "# python -m tensorflow.python.debug.cli.offline_analyzer --dump_dir=\"tfdbg_dumps/run_<epoch_timestamp_microsec>_<uuid>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics like compute time or memory.\n",
    "# Need to pass run_options and run_metadata to sess.run().\n",
    "# Not possible with Experiment and Estimator API.\n",
    "#run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "#run_metadata = tf.RunMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_DIR = os.path.join('..', 'logdir', 'structured_sequence', 'run1')\n",
    "MODEL_DIR = 'structured_sequence'\n",
    "config = tflearn.RunConfig(\n",
    "    save_checkpoints_secs=60,\n",
    "    # save_summary_steps=100,\n",
    "    model_dir=MODEL_DIR,\n",
    "    # To see device placement. It unfortunately only shows up in stderr, not Tensorboard (explicit placement only).\n",
    "    # session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=True),\n",
    ")\n",
    "hparams = {\n",
    "    'learning_rate': 0.01\n",
    "}\n",
    "estimator = tflearn.Estimator(model_fn=model, config=config, params=hparams)\n",
    "#estimator.fit(input_fn=DataLoader(filenames=['train.tfrecords']))\n",
    "#estimator.evaluate(input_fn=DataLoader(filenames=['validation.tfrecords']))\n",
    "\n",
    "experiment = tflearn.Experiment(\n",
    "    estimator,\n",
    "    eval_steps=None,\n",
    "    train_input_fn=DataLoader(['train.tfrecords'], num_epochs=10),\n",
    "    eval_input_fn=DataLoader(['validation.tfrecords']),\n",
    ")\n",
    "\n",
    "shutil.rmtree(MODEL_DIR, ignore_errors=True)  # Start fresh each time.\n",
    "experiment.train_and_evaluate()\n",
    "#experiment.continuous_train_and_eval()  # Takes less ressources.\n",
    "\n",
    "#estimator.evaluate(input_fn=DataLoader(filenames=['test.tfrecords']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, inputs, states, laplacian):\n",
    "        \"\"\"Fully connected layer with Mout features.\"\"\"\n",
    "        N, Min = x.get_shape()\n",
    "        W = self._weight_variable([int(Min), self.Mout], regularization=True)\n",
    "        b = self._bias_variable([self.Mout], regularization=True)\n",
    "        x = tf.matmul(x, W) + b\n",
    "        return tf.nn.relu(x) if self.relu else x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Inherit from RNNCell to use high level TF machinery like `tf.dynamic_rnn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM:\n",
    "    \"\"\"The network is not unrolled.\"\"\"\n",
    "    \n",
    "    def _input_conv(self, x, w, b=None):\n",
    "        pass\n",
    "    \n",
    "    def _reccurent_conv(self, x, w, b=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import control_flow_ops\n",
    "control_flow_ops.while_loop(\n",
    "    cond=lambda time, *_: time < time_steps,\n",
    "    body=_step,\n",
    "    loop_vars=(time, output_ta) + states,\n",
    "    parallel_iterations=32,\n",
    "    swap_memory=True)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}