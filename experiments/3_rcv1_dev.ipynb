{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_string('dir_data', 'data_rcv1', 'Directory to store data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Dropout (Bruna did the same)**\n",
    "\n",
    "We took the dataset and split it into 63 classes based on the the 63 categories at the second-level of the category tree. We removed 11 categories that did not have any data and one category that had only 4 training examples. We also removed one category that covered a huge chunk (25%) of the examples. This left us with 50 classes and 402,738 documents. We divided the documents into equal-sized training and test sets randomly. Each document was represented\n",
    "using the 2000 most frequent non-stopwords in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset.\n",
    "rcv1 = sklearn.datasets.fetch_rcv1('data_rcv1')\n",
    "N, C = rcv1.target.shape\n",
    "print('N={} documents, C={} classes'.format(N, C))\n",
    "\n",
    "#def select_classes\n",
    "\n",
    "# All classes.\n",
    "class_names = ['C11', 'C12', 'C13','C14','C15','C151','C1511','C152','C16','C17',\n",
    "               'C171','C172','C173','C174','C18','C181','C182','C183','C21','C22',\n",
    "               'C23','C24','C31', 'C311','C312','C313','C32','C33','C331','C34',\n",
    "               'C41','C411','C42','CCAT','E11', 'E12','E121','E13','E131','E132',\n",
    "               'E14','E141','E142','E143','E21', 'E211','E212','E31','E311','E312',\n",
    "               'E313','E41','E411','E51','E511','E512','E513','E61','E71','ECAT',\n",
    "               'G15','G151','G152','G153','G154','G155','G156','G157','G158','G159',\n",
    "               'GCAT','GCRIM','GDEF','GDIP','GDIS','GENT','GENV','GFAS','GHEA',\n",
    "               'GJOB','GMIL','GOBIT','GODD','GPOL','GPRO','GREL','GSCI','GSPO',\n",
    "               'GTOUR','GVIO','GVOTE','GWEA','GWELF','M11','M12','M13','M131',\n",
    "               'M132','M14','M141','M142','M143','MCAT']\n",
    "assert len(class_names) == 103  # There is 103 categories according to LYRL2004.\n",
    "\n",
    "# Second-level classes.\n",
    "keep = ['C11','C12','C13','C14','C15','C16','C17','C18','C21','C22','C23','C24',\n",
    "        'C31','C32','C33','C34','C41','C42','E11','E12','E13','E14','E21','E31',\n",
    "        'E41','E51','E61','E71','G15','GCRIM','GDEF','GDIP','GDIS','GENT','GENV',\n",
    "        'GFAS','GHEA','GJOB','GMIL','GOBIT','GODD','GPOL','GPRO','GREL','GSCI',\n",
    "        'GSPO','GTOUR','GVIO','GVOTE','GWEA','GWELF','M11','M12','M13','M14']\n",
    "assert len(keep) == 55  # There is 55 second-level categories according to LYRL2004.\n",
    "keep.remove('C15')   # 151785 documents\n",
    "keep.remove('GMIL')  # 5 documents only\n",
    "\n",
    "# Construct a lookup table for labels.\n",
    "labels_row = []\n",
    "labels_col = []\n",
    "class_lookup = {}\n",
    "for i,name in enumerate(class_names):\n",
    "    class_lookup[name] = i\n",
    "\n",
    "# Index of classes to keep.\n",
    "idx_keep = np.empty(len(keep))\n",
    "for i,cat in enumerate(keep):\n",
    "    idx_keep[i] = class_lookup[cat]\n",
    "target = rcv1.target[:,idx_keep]\n",
    "\n",
    "# Number of documents per class.\n",
    "def show_doc_per_class(names, target, print_=False):\n",
    "    docs_per_class = np.array(target.astype(np.uint64).sum(axis=0)).squeeze()\n",
    "    print('categories ({} assignments in total)'.format(docs_per_class.sum()))\n",
    "    if print_:\n",
    "        for i,cat in enumerate(names):\n",
    "            print('  {:5s}: {:6d} documents'.format(cat, docs_per_class[i]))\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.plot(sorted(docs_per_class[::-1]),'.')\n",
    "show_doc_per_class(rcv1.target_names, rcv1.target)\n",
    "show_doc_per_class(keep, target, True)\n",
    "\n",
    "#def select_documents\n",
    "\n",
    "# Number of classes per document.\n",
    "def show_classes_per_doc(target):\n",
    "    classes_per_doc = np.array(target.sum(axis=1)).squeeze()\n",
    "    plt.figure(figsize=(17,5))\n",
    "    plt.plot(sorted(classes_per_doc[::-1]),'.')\n",
    "    return classes_per_doc\n",
    "classes_per_doc = show_classes_per_doc(rcv1.target)\n",
    "classes_per_doc = show_classes_per_doc(target)\n",
    "\n",
    "target = target[classes_per_doc==1]\n",
    "data = rcv1.data[classes_per_doc==1, :]\n",
    "\n",
    "# Convert labels from indicator form to single value.\n",
    "N, C = target.shape\n",
    "assert C == len(keep)\n",
    "target = target.tocoo()\n",
    "target = target.col\n",
    "assert target.min() == 0\n",
    "assert target.max() == C - 1\n",
    "\n",
    "# Bruna and Dropout used 2 * 201369 = 402738 documents. Probably the difference btw v1 and v2.\n",
    "print('N = {} documents and C = {} classes left'.format(N, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "n = 0\n",
    "for path, subdirs, files in os.walk('data_rcv1/rcv1/'):\n",
    "    for file in files:\n",
    "        if 'newsML.xml' in file:\n",
    "            root = ET.parse(os.path.join(path, file)).getroot()\n",
    "            date = root.attrib['date']\n",
    "            dates.append(date)\n",
    "            n+=1\n",
    "print(n)\n",
    "print(len(dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "root = ET.parse('data_rcv1/rcv1/19960820/2286newsML.xml').getroot()\n",
    "date = root.attrib['date']\n",
    "\n",
    "# Fetch textual content.\n",
    "text = root.find('title').text\n",
    "for p in root.find('text').findall('p'):\n",
    "    text = ' '.join((text, p.text))\n",
    "print(text)\n",
    "\n",
    "# Find the labels of a document.\n",
    "classes = []\n",
    "doc = 0\n",
    "for codes in root.find('metadata').findall('codes'):\n",
    "    if codes.attrib['class'] == 'bip:topics:1.0':\n",
    "        for code in codes.findall('code'):\n",
    "            labels_row.append(doc)\n",
    "            labels_col.append(class_lookup[code.attrib['code']])\n",
    "            classes.append(code.attrib['code'])\n",
    "\n",
    "assert len(labels_row) == len(labels_col)\n",
    "labels_val = np.ones(len(labels_row), dtype=np.bool)\n",
    "labels = scipy.sparse.csr_matrix((labels_val, (labels_row, labels_col)))\n",
    "\n",
    "print(labels)\n",
    "labels.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From LYRL2004 Appendix 3\n",
    "http://jmlr.csail.mit.edu/papers/volume5/lewis04a/a03-expanded-topics-hierarchy/rcv1.topics.hier.expanded\n",
    "\n",
    "parent: C1      child: C11     child-description: STRATEGY/PLANS\n",
    "parent: C1      child: C12     child-description: LEGAL/JUDICIAL\n",
    "parent: C1      child: C13     child-description: REGULATION/POLICY\n",
    "parent: C1      child: C14     child-description: SHARE LISTINGS\n",
    "parent: C1      child: C15     child-description: PERFORMANCE\n",
    "parent: C1      child: C16     child-description: INSOLVENCY/LIQUIDITY\n",
    "parent: C1      child: C17     child-description: FUNDING/CAPITAL\n",
    "parent: C1      child: C18     child-description: OWNERSHIP CHANGES\n",
    "parent: C2      child: C21     child-description: PRODUCTION/SERVICES\n",
    "parent: C2      child: C22     child-description: NEW PRODUCTS/SERVICES\n",
    "parent: C2      child: C23     child-description: RESEARCH/DEVELOPMENT\n",
    "parent: C2      child: C24     child-description: CAPACITY/FACILITIES\n",
    "parent: C3      child: C31     child-description: MARKETS/MARKETING\n",
    "parent: C3      child: C32     child-description: ADVERTISING/PROMOTION\n",
    "parent: C3      child: C33     child-description: CONTRACTS/ORDERS\n",
    "parent: C3      child: C34     child-description: MONOPOLIES/COMPETITION\n",
    "parent: C4      child: C41     child-description: MANAGEMENT\n",
    "parent: C4      child: C42     child-description: LABOUR\n",
    "parent: E1      child: E11     child-description: ECONOMIC PERFORMANCE\n",
    "parent: E1      child: E12     child-description: MONETARY/ECONOMIC\n",
    "parent: E1      child: E13     child-description: INFLATION/PRICES\n",
    "parent: E1      child: E14     child-description: CONSUMER FINANCE\n",
    "parent: E2      child: E21     child-description: GOVERNMENT FINANCE\n",
    "parent: E3      child: E31     child-description: OUTPUT/CAPACITY\n",
    "parent: E4      child: E41     child-description: EMPLOYMENT/LABOUR\n",
    "parent: E5      child: E51     child-description: TRADE/RESERVES\n",
    "parent: E6      child: E61     child-description: HOUSING STARTS\n",
    "parent: E7      child: E71     child-description: LEADING INDICATORS\n",
    "parent: G1      child: G15     child-description: EUROPEAN COMMUNITY\n",
    "parent: GCAT    child: GCRIM   child-description: CRIME, LAW ENFORCEMENT\n",
    "parent: GCAT    child: GDEF    child-description: DEFENCE\n",
    "parent: GCAT    child: GDIP    child-description: INTERNATIONAL RELATIONS\n",
    "parent: GCAT    child: GDIS    child-description: DISASTERS AND ACCIDENTS\n",
    "parent: GCAT    child: GENT    child-description: ARTS, CULTURE, ENTERTAINMENT\n",
    "parent: GCAT    child: GENV    child-description: ENVIRONMENT AND NATURAL WORLD\n",
    "parent: GCAT    child: GFAS    child-description: FASHION\n",
    "parent: GCAT    child: GHEA    child-description: HEALTH\n",
    "parent: GCAT    child: GJOB    child-description: LABOUR ISSUES\n",
    "parent: GCAT    child: GMIL    child-description: MILLENNIUM ISSUES\n",
    "parent: GCAT    child: GOBIT   child-description: OBITUARIES\n",
    "parent: GCAT    child: GODD    child-description: HUMAN INTEREST\n",
    "parent: GCAT    child: GPOL    child-description: DOMESTIC POLITICS\n",
    "parent: GCAT    child: GPRO    child-description: BIOGRAPHIES, PERSONALITIES, PEOPLE\n",
    "parent: GCAT    child: GREL    child-description: RELIGION\n",
    "parent: GCAT    child: GSCI    child-description: SCIENCE AND TECHNOLOGY\n",
    "parent: GCAT    child: GSPO    child-description: SPORTS\n",
    "parent: GCAT    child: GTOUR   child-description: TRAVEL AND TOURISM\n",
    "parent: GCAT    child: GVIO    child-description: WAR, CIVIL WAR\n",
    "parent: GCAT    child: GVOTE   child-description: ELECTIONS\n",
    "parent: GCAT    child: GWEA    child-description: WEATHER\n",
    "parent: GCAT    child: GWELF   child-description: WELFARE, SOCIAL SERVICES\n",
    "parent: M1      child: M11     child-description: EQUITY MARKETS\n",
    "parent: M1      child: M12     child-description: BOND MARKETS\n",
    "parent: M1      child: M13     child-description: MONEY MARKETS\n",
    "parent: M1      child: M14     child-description: COMMODITY MARKETS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
